{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def countDays(row):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    a = datetime.strptime(row[\"launched\"][:10], date_format)\n",
    "    b = datetime.strptime(row[\"deadline\"], date_format)\n",
    "    delta = b - a\n",
    "    return delta.days\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(H, Y, beta=1.0):\n",
    "    tp = sum((Y == H) * (Y == 1) * 1)\n",
    "    tn = sum((Y == H) * (Y == 0) * 1)\n",
    "    fp = sum((Y != H) * (Y == 0) * 1)\n",
    "    fn = sum((Y != H) * (Y == 1) * 1)\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (fp + tn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = sensitivity\n",
    "    f_score = ( (beta**2 + 1) * precision * recall) / (beta**2 * precision + recall)\n",
    "    auc = (sensitivity + specificity) / 2\n",
    "    youden = sensitivity - (1 - specificity)\n",
    "    p_plus = sensitivity / (1 - specificity)\n",
    "    p_minus = (1 - sensitivity) / specificity\n",
    "    dp = (np.sqrt(3) / np.pi) * (np.log(sensitivity/(1 - sensitivity) + np.log(specificity/(1 - specificity))))\n",
    "    \n",
    "    result = {}\n",
    "    result[\"tp\"] = tp\n",
    "    result[\"tn\"] = tn\n",
    "    result[\"fp\"] = fp\n",
    "    result[\"fn\"] = fn\n",
    "    result[\"accuracy\"] = accuracy\n",
    "    result[\"sensitivity\"] = sensitivity\n",
    "    result[\"specificity\"] = specificity\n",
    "    result[\"precision\"] = precision\n",
    "    result[\"recall\"] = recall\n",
    "    result[\"f-score\"] = f_score\n",
    "    result[\"AUC\"] = auc\n",
    "    result[\"Youden\"] = youden\n",
    "    result[\"p+\"] = p_plus\n",
    "    result[\"p-\"] = p_minus\n",
    "    result[\"DP\"] = dp\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ks-projects-201801.csv')\n",
    "data = df[(df.state == 'successful') | (df.state == 'failed') ]\n",
    "data[\"days\"] = data.apply(countDays, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData = data.drop(['ID', 'name','category','deadline','launched','pledged','usd pledged','goal', 'backers', 'usd_pledged_real'], 1)\n",
    "dataBinary = cleanData.copy()\n",
    "dataBinary['state'] = np.where(dataBinary.state=='successful', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(dataBinary['main_category'])\n",
    "dataBinary = dataBinary.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(dataBinary['currency'])\n",
    "dataBinary = dataBinary.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(dataBinary['country'])\n",
    "dataBinary = dataBinary.join(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDataBinary = dataBinary.drop(['main_category', 'currency','country'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotData = cleanDataBinary.copy()\n",
    "X_set = OneHotData.drop(['state'], 1)\n",
    "y_set = OneHotData['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_set, y_set, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassifierName(model):\n",
    "    print(type(model).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def runClassifier(clf, X_train, y_train,X_test, y_test):\n",
    "    print(f\"** {printClassifierName(clf)}\")\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time()\n",
    "    print(f\"\\tTraining time:\\t\\t{t1-t0:3.3f}\")\n",
    "    score_train = clf.score(X_train[0:50000], y_train[0:50000])\n",
    "    t2 = time()\n",
    "    print(f\"\\tPrediction time(train):\\t{t2-t1:3.3f}\")\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "    t3 = time()\n",
    "    print(f\"\\tPrediction time(test):\\t{t3-t2:3.3f}\")\n",
    "    print(f\"\\tScore Train: {score_train:.3f}\\tScore Test: {score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "** None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining time:\t\t1.075\n",
      "\tPrediction time(train):\t0.031\n",
      "\tPrediction time(test):\t0.047\n",
      "\tScore Train: 0.598\tScore Test: 0.595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression = LogisticRegression()\n",
    "runClassifier(LogisticRegression, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "hidden_layer_size = [(100,100,100),(200,200,200),(500,500,500)]\n",
    "for hls in hidden_layer_size:\n",
    "    print(\"hidden_layer_sizes:\" + str(hls))\n",
    "    cls = MLPClassifier(hidden_layer_sizes=hls)\n",
    "    runClassifier(cls, X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=100)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def convertStringsToInt(X_set):\n",
    "    for column in X_set.columns:\n",
    "        if X_set[column].dtype == type(object):\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            X_set[column] = le.fit_transform(X_set[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBinary2 = cleanData.copy()\n",
    "dataBinary2['state'] = np.where(dataBinary2.state=='successful', 1, 0)\n",
    "y_set2= dataBinary2['state']\n",
    "X_set2 = dataBinary2.drop(['state'], 1)\n",
    "convertStringsToInt(X_set2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_set2, y_set2, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = [(100,100,100)]#,(200,200,200),(500,500,500)]\n",
    "for hls in hidden_layer_size:\n",
    "    print(\"hidden_layer_sizes:\" + str(hls))\n",
    "    cls = MLPClassifier(hidden_layer_sizes=hls)\n",
    "    runClassifier(cls, X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=100)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "** None\n",
      "\tTraining time:\t\t751.966\n",
      "\tPrediction time(train):\t0.348\n",
      "\tPrediction time(test):\t0.405\n",
      "\tScore Train: 0.648\tScore Test: 0.651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "runClassifier(mlp,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2209184550206671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:180: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(mlp.predict(X_test), y_test)\n",
    "print(result['Youden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "** None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining time:\t\t1.185\n",
      "\tPrediction time(train):\t0.047\n",
      "\tPrediction time(test):\t0.023\n",
      "\tScore Train: 0.598\tScore Test: 0.595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression()\n",
    "runClassifier(logReg,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "** None\n",
      "\tTraining time:\t\t6.764\n",
      "\tPrediction time(train):\t13.009\n",
      "\tPrediction time(test):\t16.964\n",
      "\tScore Train: 0.685\tScore Test: 0.612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNClassifier = KNeighborsClassifier()\n",
    "runClassifier(KNClassifier,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18071371544578008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:180: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(KNClassifier.predict(X_test), y_test)\n",
    "print(result['Youden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "** None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining time:\t\t1.166\n",
      "\tPrediction time(train):\t0.043\n",
      "\tPrediction time(test):\t0.053\n",
      "\tScore Train: 0.598\tScore Test: 0.595\n"
     ]
    }
   ],
   "source": [
    "runClassifier(logReg,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "** None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining time:\t\t1.088\n",
      "\tPrediction time(train):\t0.090\n",
      "\tPrediction time(test):\t0.172\n",
      "\tScore Train: 0.602\tScore Test: 0.599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randFor = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "runClassifier(randFor,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010521852764188414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:180: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(randFor.predict(X_test), y_test)\n",
    "print(result['Youden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randFor = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "runClassifier(randFor,X_train, y_train, X_test, y_test)\n",
    "randFor.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(0.52342,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfiers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_sizes:(50,)\n",
      "MLPClassifier\n",
      "** None\n",
      "\tTraining time:\t\t217.220\n",
      "\tPrediction time(train):\t0.163\n",
      "\tPrediction time(test):\t0.247\n",
      "\tScore Train: 0.539\tScore Test: 0.540\n",
      "hidden_layer_sizes:(75,)\n",
      "MLPClassifier\n",
      "** None\n",
      "\tTraining time:\t\t456.205\n",
      "\tPrediction time(train):\t0.263\n",
      "\tPrediction time(test):\t0.339\n",
      "\tScore Train: 0.602\tScore Test: 0.599\n",
      "hidden_layer_sizes:(100,)\n",
      "MLPClassifier\n",
      "** None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining time:\t\t800.386\n",
      "\tPrediction time(train):\t0.350\n",
      "\tPrediction time(test):\t0.418\n",
      "\tScore Train: 0.602\tScore Test: 0.599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "hidden_layer_size = [(50,),(75,),(100,)]#, (25,25), (25,50), (50,50), (50,75), (25,75), (25,100), (100, 25)]\n",
    "for hls in hidden_layer_size:\n",
    "    print(\"hidden_layer_sizes:\" + str(hls))\n",
    "    cls = MLPClassifier(activation='relu', solver='adam', hidden_layer_sizes= hls)\n",
    "    runClassifier(cls, X_train, y_train,X_test, y_test)\n",
    "    classfiers.append(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classfiers:\n",
    "    result = evaluate(clf.predict(X_test), y_test)\n",
    "    print(result['Youden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
