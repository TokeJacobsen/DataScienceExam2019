{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def countDays(row):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    a = datetime.strptime(row[\"launched\"][:10], date_format)\n",
    "    b = datetime.strptime(row[\"deadline\"], date_format)\n",
    "    delta = b - a\n",
    "    return delta.days\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(H, Y, beta=1.0):\n",
    "    tp = sum((Y == H) * (Y == 1) * 1)\n",
    "    tn = sum((Y == H) * (Y == 0) * 1)\n",
    "    fp = sum((Y != H) * (Y == 0) * 1)\n",
    "    fn = sum((Y != H) * (Y == 1) * 1)\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (fp + tn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = sensitivity\n",
    "    f_score = ( (beta**2 + 1) * precision * recall) / (beta**2 * precision + recall)\n",
    "    auc = (sensitivity + specificity) / 2\n",
    "    youden = sensitivity - (1 - specificity)\n",
    "    p_plus = sensitivity / (1 - specificity)\n",
    "    p_minus = (1 - sensitivity) / specificity\n",
    "    dp = (np.sqrt(3) / np.pi) * (np.log(sensitivity/(1 - sensitivity) + np.log(specificity/(1 - specificity))))\n",
    "    \n",
    "    result = {}\n",
    "    result[\"tp\"] = tp\n",
    "    result[\"tn\"] = tn\n",
    "    result[\"fp\"] = fp\n",
    "    result[\"fn\"] = fn\n",
    "    result[\"accuracy\"] = accuracy\n",
    "    result[\"sensitivity\"] = sensitivity\n",
    "    result[\"specificity\"] = specificity\n",
    "    result[\"precision\"] = precision\n",
    "    result[\"recall\"] = recall\n",
    "    result[\"f-score\"] = f_score\n",
    "    result[\"AUC\"] = auc\n",
    "    result[\"Youden\"] = youden\n",
    "    result[\"p+\"] = p_plus\n",
    "    result[\"p-\"] = p_minus\n",
    "    result[\"DP\"] = dp\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ks-projects-201801.csv')\n",
    "data = df[(df.state == 'successful') | (df.state == 'failed') ]\n",
    "data[\"days\"] = data.apply(countDays, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData = data.drop(['ID', 'name','category','deadline','launched','pledged','usd pledged','goal', 'backers', 'usd_pledged_real'], 1)\n",
    "dataBinary = cleanData.copy()\n",
    "dataBinary['state'] = np.where(dataBinary.state=='successful', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(dataBinary['main_category'])\n",
    "dataBinary = dataBinary.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(dataBinary['currency'])\n",
    "dataBinary = dataBinary.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(dataBinary['country'])\n",
    "dataBinary = dataBinary.join(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDataBinary = dataBinary.drop(['main_category', 'currency','country'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotData = cleanDataBinary.copy()\n",
    "X_set = OneHotData.drop(['state'], 1)\n",
    "y_set = OneHotData['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_set, y_set, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassifierName(model):\n",
    "    print(type(model).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def runClassifier(clf, X_train, y_train,X_test, y_test):\n",
    "    print(f\"** {printClassifierName(clf)}\")\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time()\n",
    "    print(f\"\\tTraining time:\\t\\t{t1-t0:3.3f}\")\n",
    "    score_train = clf.score(X_train[0:50000], Y_train[0:50000])\n",
    "    t2 = time()\n",
    "    print(f\"\\tPrediction time(train):\\t{t2-t1:3.3f}\")\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "    t3 = time()\n",
    "    print(f\"\\tPrediction time(test):\\t{t3-t2:3.3f}\")\n",
    "    print(f\"\\tScore Train: {score_train:.3f}\\tScore Test: {score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** <function printClassifierName at 0x00000232A5861E18>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\den udvalgte\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining time:\t\t1.200\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a44fa2b2d95a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLogisticRegression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrunClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-596df6a05d47>\u001b[0m in \u001b[0;36mrunClassifier\u001b[1;34m(clf, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\tTraining time:\\t\\t{t1-t0:3.3f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mscore_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\tPrediction time(train):\\t{t2-t1:3.3f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression = LogisticRegression()\n",
    "runClassifier(LogisticRegression, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
